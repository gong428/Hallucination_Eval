# config.yaml

model:
  name: "llama3"
  path: "meta-llama/Meta-Llama-3-8B-Instruct" 
  inference_method: "uqlm" 

  model_kwargs:
    torch_dtype: "bfloat16"   # "float16", "bfloat16", "float32" ë“±
    load_in_4bit: true      # 4ë¹„íŠ¸ ì–‘ìí™” í™œì„±í™”
    # load_in_8bit: false     # 8ë¹„íŠ¸ ì–‘ìí™” ì˜µì…˜
    # bnb_4bit_quant_type: "nf4"
    # bnb_4bit_compute_dtype: "bfloat16"

  # ğŸ†• ì¶”ë¡  ë°©ì‹ì— ê´€ê³„ì—†ì´ ê³µí†µìœ¼ë¡œ ì‚¬ìš©ë  íŒŒë¼ë¯¸í„° ë¸”ë¡
  inference_params:
    max_new_tokens: 64
    temperature: 1
    top_p: 0.9
    scorers:
      - "min_probability"
      - "normalized_probability"
    # ğŸ†• ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: ëª¨ë¸ì˜ ì „ë°˜ì ì¸ ì—­í• ê³¼ ë‹µë³€ ìŠ¤íƒ€ì¼ì„ ì§€ì •í•©ë‹ˆë‹¤.
    system_prompt: " "
    # "You are an expert at solving math word problems. Provide only the final numerical answer without any extra text or explanation."
    # í…œí”Œë¦¿ì„ ì˜ì–´ë¡œ ë²ˆì—­í•˜ê³  YAML ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ í•œ ì¤„ë¡œ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.
    user_prompt_template: "When you solve this math problem only return the answer with no additional text.\n{question}"
    
    # ë§Œì•½ 'ours' ë°©ì‹ì—ë§Œ í•„ìš”í•œ íŒŒë¼ë¯¸í„°ê°€ ìˆë‹¤ë©´ ì—¬ê¸°ì— ì¶”ê°€í•©ë‹ˆë‹¤.
    # custom_threshold: 0.75
    # beam_size: 5
# --- í‰ê°€í•  ë°ì´í„°ì…‹ ëª©ë¡ ---
# ì—¬ê¸°ì— ë°ì´í„°ì…‹ ì´ë¦„ì„ ì¶”ê°€í•˜ê±°ë‚˜ ì œê±°í•˜ì—¬ í‰ê°€ ëŒ€ìƒì„ ì œì–´í•©ë‹ˆë‹¤.
datasets:
  #gsm8k:
  #  type: "math"
  #svamp:
  #  type: "math"
  #csqa:
  #  type: "exact_match"
  #ai2_arc:
  #  type: "exact_match"
  halu_eval_qa:
    type : "open_domain"
  #nq_open:
  #  type : "open_domain"
  #popqa:
  #  type : "open_domain"

# --- ìƒ˜í”Œë§ ì„¤ì • ---
# ê° ë°ì´í„°ì…‹ì—ì„œ ë¡œë“œí•  ìƒ˜í”Œì˜ ìˆ˜
# null ë¡œ ì„¤ì •í•˜ë©´ ì „ì²´ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
sample_num: 10

# --- ê²°ê³¼ ì €ì¥ ê²½ë¡œ ---
results_dirs:
  model_outputs: "results/model_outputs"
  metrics: "results/metrics"